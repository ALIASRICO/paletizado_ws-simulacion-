# Pruebas de VisiÃ³n - YOLOv8-OBB para DOBOT CR20V

Sistema de detecciÃ³n de objetos usando YOLOv8-OBB (Oriented Bounding Box) para el robot DOBOT CR20V.

## ğŸ“¦ Estructura

```
pruebas_de_vision/
â”œâ”€â”€ pruebas_de_vision/
â”‚   â”œâ”€â”€ camera_viewer.py      # Visualizador de cÃ¡mara Gazebo
â”‚   â”œâ”€â”€ train_yolo.py         # Script de entrenamiento YOLO
â”‚   â””â”€â”€ yolo_detector.py      # Nodo ROS2 de detecciÃ³n
â”œâ”€â”€ launch/
â”‚   â”œâ”€â”€ camera_test.launch.py # Launch de cÃ¡mara Gazebo
â”‚   â”œâ”€â”€ yolo_detection.launch.py
â”‚   â””â”€â”€ yolo_detection_venv.launch.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_yolo_venv.sh    # Script de entrenamiento con venv
â”‚   â””â”€â”€ run_yolo_detector_venv.sh
â””â”€â”€ worlds/
    â””â”€â”€ camera_test.sdf       # Mundo Gazebo con cÃ¡mara
```

## ğŸ”§ InstalaciÃ³n

### 1. Crear Entorno Virtual (YA HECHO)

```bash
cd ~/dobot_ws
python3 -m venv yolo_venv
```

### 2. Instalar Dependencias en el Venv

```bash
~/dobot_ws/yolo_venv/bin/pip install ultralytics roboflow opencv-python numpy
```

### 3. Compilar Paquete ROS2

```bash
cd ~/dobot_ws
colcon build --packages-select pruebas_de_vision --symlink-install
source install/setup.bash
```

## ğŸš€ Uso

### OpciÃ³n A: Usando Scripts de Conveniencia

#### Entrenar Modelo (con entorno virtual)

```bash
# Usar script de conveniencia
~/dobot_ws/src/pruebas_de_vision/scripts/train_yolo_venv.sh
```

#### Ejecutar DetecciÃ³n

```bash
# Primero lanzar Gazebo con cÃ¡mara
ros2 launch pruebas_de_vision camera_test.launch.py

# En otra terminal, ejecutar detector
~/dobot_ws/src/pruebas_de_vision/scripts/run_yolo_detector_venv.sh
```

### OpciÃ³n B: Comandos Manuales

#### Entrenar Modelo

```bash
# Activar entorno virtual y ejecutar
~/dobot_ws/yolo_venv/bin/python3 ~/dobot_ws/src/pruebas_de_vision/pruebas_de_vision/train_yolo.py
```

#### Ejecutar DetecciÃ³n con Gazebo

```bash
# Terminal 1: Source ROS2 y lanzar Gazebo
source ~/dobot_ws/install/setup.bash
ros2 launch pruebas_de_vision camera_test.launch.py

# Terminal 2: Ejecutar detector con venv
source ~/dobot_ws/install/setup.bash
~/dobot_ws/yolo_venv/bin/python3 ~/dobot_ws/src/pruebas_de_vision/pruebas_de_vision/yolo_detector.py
```

### OpciÃ³n C: Launch File Integrado

```bash
source ~/dobot_ws/install/setup.bash
ros2 launch pruebas_de_vision yolo_detection_venv.launch.py
```

## ğŸ“¡ Topics

### Publicados por el Detector

| Topic | Tipo | DescripciÃ³n |
|-------|------|-------------|
| `/vision/detections/image` | sensor_msgs/Image | Imagen con detecciones anotadas |
| `/vision/detections/poses` | geometry_msgs/PoseArray | Poses 2D de objetos detectados |
| `/vision/detections/bboxes` | vision_msgs/Detection2DArray | Bounding boxes orientados |

### Suscritos

| Topic | Tipo | DescripciÃ³n |
|-------|------|-------------|
| `/camera/color/image_raw` | sensor_msgs/Image | Imagen de cÃ¡mara Gazebo |

## âš™ï¸ ParÃ¡metros

El detector acepta los siguientes parÃ¡metros:

```bash
# LÃ­nea de comandos
~/dobot_ws/yolo_venv/bin/python3 yolo_detector.py \
    --model /path/to/best.pt \
    --confidence 0.5 \
    --iou 0.5 \
    --image-topic /camera/color/image_raw \
    --show-window
```

| ParÃ¡metro | Default | DescripciÃ³n |
|-----------|---------|-------------|
| `--model` | yolov8n-obb.pt | Ruta al modelo YOLO |
| `--confidence` | 0.25 | Umbral de confianza mÃ­nima |
| `--iou` | 0.5 | Umbral IOU para NMS |
| `--image-topic` | /camera/color/image_raw | Topic de imagen |
| `--show-window` | True | Mostrar ventana OpenCV |
| `--no-window` | - | Desactivar ventana |

## ğŸ¯ Dataset

El modelo se entrena con el dataset **Kartonger** de Roboflow:
- **Workspace**: jugos
- **Project**: kartonger-8b52f
- **Clases**: Cajas de cartÃ³n

## ğŸ“ Modelos Entrenados

DespuÃ©s del entrenamiento, los modelos se guardan en:

```
~/dobot_ws/runs/obb/kartonger_yolov8l/
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt      # Mejor modelo (usar este)
â”‚   â”œâ”€â”€ last.pt      # Ãšltima Ã©poca
â”‚   â””â”€â”€ best.onnx    # Exportado a ONNX
â”œâ”€â”€ results.csv      # MÃ©tricas de entrenamiento
â””â”€â”€ results.png      # GrÃ¡ficas de rendimiento
```

## ğŸ” Verificar InstalaciÃ³n

```bash
# Verificar que el entorno virtual tiene las dependencias
~/dobot_ws/yolo_venv/bin/python3 -c "from ultralytics import YOLO; print('âœ… YOLO OK')"

# Verificar que ROS2 ve el paquete
source ~/dobot_ws/install/setup.bash
ros2 pkg list | grep pruebas_de_vision
```

## âš ï¸ Notas Importantes

1. **NO instales ultralytics en el sistema** - Usa siempre el entorno virtual
2. **El entorno virtual estÃ¡ en** `~/dobot_ws/yolo_venv`
3. **COLCON_IGNORE** estÃ¡ configurado para que colcon ignore el venv
4. **Source ROS2** antes de usar cualquier comando ros2

## ğŸ› Troubleshooting

### Error: "ultralytics not found"

```bash
# Verificar instalaciÃ³n en venv
~/dobot_ws/yolo_venv/bin/pip list | grep ultralytics

# Si no estÃ¡, instalar
~/dobot_ws/yolo_venv/bin/pip install ultralytics
```

### Error: "No module named 'rclpy'"

El detector necesita ROS2. AsegÃºrate de hacer source:

```bash
source ~/dobot_ws/install/setup.bash
```

### Gazebo no muestra cÃ¡mara

```bash
# Verificar que el bridge estÃ¡ funcionando
ros2 topic list | grep camera

# Verificar imÃ¡genes
ros2 topic hz /camera/color/image_raw
```

## ğŸ“Š MÃ©tricas de Entrenamiento

El entrenamiento robusto usa:
- **Ã‰pocas**: 100 (con early stopping)
- **Batch size**: 16
- **Optimizer**: AdamW
- **AugmentaciÃ³n**: Mosaic, MixUp, Copy-Paste
- **Learning rate**: 0.001

Tiempo estimado: 2-4 horas en GPU, 8-12 horas en CPU.
